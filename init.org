#+TITLE: [[https://www.kaggle.com/c/titanic/overview][Titanic]]

* Get the Data
  - Def
    #+BEGIN_SRC python :results output :session init :tangle yes :export code
    import os
    import subprocess

    KAGGEL_CMD = "kaggle competitions download -c titanic"
    LOCAL_DATA_PATH = "./dataset/"

    if not os.path.isdir(LOCAL_DATA_PATH):
      os.mkdir(LOCAL_DATA_PATH)

    project_root = os.getcwd()
    print(project_root)
    os.chdir(LOCAL_DATA_PATH)
    subprocess.call(KAGGEL_CMD.split(" "))
    os.chdir(project_root)
    #+END_SRC

    #+RESULTS:

* Load Libraries and Data
   #+BEGIN_SRC python :results value :session init :tangle yes
   import pandas as pd
   import numpy as np

   LOCAL_DATA_PATH = "./dataset/"
   train_data_csv = pd.read_csv(os.path.join(LOCAL_DATA_PATH, "train.csv"))

   from sklearn.preprocessing import LabelEncoder, LabelBinarizer, StandardScaler
   #+END_SRC

   #+RESULTS:

* Peek Data
  - head
    #+BEGIN_SRC python :results value :session init :tangle yes
    pd.set_option('display.max_columns', None)
    pd.set_option('display.width', 200)
    train_data_csv.head(10)
    #+END_SRC

    #+RESULTS:
    #+begin_example
       PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked
    0            1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   7.2500   NaN        S
    1            2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599  71.2833   C85        C
    2            3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S
    3            4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803  53.1000  C123        S
    4            5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   8.0500   NaN        S
    5            6         0       3                                   Moran, Mr. James    male   NaN      0      0            330877   8.4583   NaN        Q
    6            7         0       1                            McCarthy, Mr. Timothy J    male  54.0      0      0             17463  51.8625   E46        S
    7            8         0       3                     Palsson, Master. Gosta Leonard    male   2.0      3      1            349909  21.0750   NaN        S
    8            9         1       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0      2            347742  11.1333   NaN        S
    9           10         1       2                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1      0            237736  30.0708   NaN        C
    #+end_example

  - info
    #+BEGIN_SRC python :results output :session init :tangle yes
    train_data_csv.info()
    #+END_SRC

    #+RESULTS:
    #+begin_example
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 891 entries, 0 to 890
    Data columns (total 12 columns):
    PassengerId    891 non-null int64
    Survived       891 non-null int64
    Pclass         891 non-null int64
    Name           891 non-null object
    Sex            891 non-null object
    Age            714 non-null float64
    SibSp          891 non-null int64
    Parch          891 non-null int64
    Ticket         891 non-null object
    Fare           891 non-null float64
    Cabin          204 non-null object
    Embarked       889 non-null object
    dtypes: float64(2), int64(5), object(5)
    memory usage: 83.6+ KB
    #+end_example

  - Interesting Columns
    - Sex
      #+BEGIN_SRC python :results output :session init :tangle yes
      train_data_csv['Sex'].value_counts()
      #+END_SRC

      #+RESULTS:
      : male      577
      : female    314
      : Name: Sex, dtype: int64

    - Pclass
      #+BEGIN_SRC python :results output :session init :tangle yes
      train_data_csv['Pclass'].value_counts()
      #+END_SRC

      #+RESULTS:
      : 3    491
      : 1    216
      : 2    184
      : Name: Pclass, dtype: int64

  - Describe
    #+BEGIN_SRC python :results output :session init :tangle yes
    train_data_csv.describe()
    #+END_SRC

    #+RESULTS:
    : PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare
    : count   891.000000  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000
    : mean    446.000000    0.383838    2.308642   29.699118    0.523008    0.381594   32.204208
    : std     257.353842    0.486592    0.836071   14.526497    1.102743    0.806057   49.693429
    : min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000
    : 25%     223.500000    0.000000    2.000000   20.125000    0.000000    0.000000    7.910400
    : 50%     446.000000    0.000000    3.000000   28.000000    0.000000    0.000000   14.454200
    : 75%     668.500000    1.000000    3.000000   38.000000    1.000000    0.000000   31.000000
    : max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200

* Preprocessing
  - Preprocessed
    #+BEGIN_SRC python :results output :session init :tangle yes
    preprocessed_data = train_data_csv
    transformations = []
    #+END_SRC

    #+RESULTS:
** Remove Unnecessary Columns
   - Name, Ticket, PassengerId, Embarked
     #+BEGIN_SRC python :results output :session init :tangle yes
     def remove_columns(data):
       data = data.drop("Name", axis=1)
       data = data.drop("Ticket", axis=1)
       data = data.drop("PassengerId", axis=1)
       data = data.drop("Embarked", axis=1)
       return data
     print((remove_columns(train_data_csv.copy())).head())
     transformations.append(remove_columns)
     #+END_SRC

     #+RESULTS:
     : Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin
     : 0         0       3    male  22.0      1      0   7.2500   NaN
     : 1         1       1  female  38.0      1      0  71.2833   C85
     : 2         1       3  female  26.0      0      0   7.9250   NaN
     : 3         1       1  female  35.0      1      0  53.1000  C123
     : 4         0       3    male  35.0      0      0   8.0500   NaN

** Missing Values
   - Cabin
     - Unprocessed Values
       #+BEGIN_SRC python :results output :session init :tangle yes
       preprocessed_data['Cabin'][:100].value_counts()
       #+END_SRC

       #+RESULTS:
       #+begin_example
       C23 C25 C27    2
       C83            1
       C85            1
       C103           1
       C52            1
       D56            1
       B28            1
       G6             1
       B30            1
       A6             1
       A5             1
       D10 D12        1
       D33            1
       F33            1
       B78            1
       E31            1
       E46            1
       F G73          1
       C123           1
       Name: Cabin, dtype: int64
       #+end_example
     - Fill ~X~
       #+BEGIN_SRC python :results output :session init :tangle yes
       def add_missing_cabin(data):
         data['Cabin'] = data['Cabin'].fillna("X")
         return data
       print(add_missing_cabin(preprocessed_data.copy()).info())
       transformations.append(add_missing_cabin)
       #+END_SRC

       #+RESULTS:
       #+begin_example
       <class 'pandas.core.frame.DataFrame'>
       RangeIndex: 891 entries, 0 to 890
       Data columns (total 12 columns):
       PassengerId    891 non-null int64
       Survived       891 non-null int64
       Pclass         891 non-null int64
       Name           891 non-null object
       Sex            891 non-null object
       Age            714 non-null float64
       SibSp          891 non-null int64
       Parch          891 non-null int64
       Ticket         891 non-null object
       Fare           891 non-null float64
       Cabin          891 non-null object
       Embarked       891 non-null object
       dtypes: float64(2), int64(5), object(5)
       memory usage: 83.6+ KB
       None
       #+end_example
   - Age
     #+BEGIN_SRC python :results output :session init :tangle yes
     def add_missing_age(data):
       data["Age"] = data["Age"].fillna(data["Age"].median())
       return data
     print(add_missing_age(train_data_csv.copy()).info())
     transformations.append(add_missing_age)
     #+END_SRC

     #+RESULTS:
     #+begin_example
     <class 'pandas.core.frame.DataFrame'>
     RangeIndex: 891 entries, 0 to 890
     Data columns (total 12 columns):
     PassengerId    891 non-null int64
     Survived       891 non-null int64
     Pclass         891 non-null int64
     Name           891 non-null object
     Sex            891 non-null object
     Age            891 non-null float64
     SibSp          891 non-null int64
     Parch          891 non-null int64
     Ticket         891 non-null object
     Fare           891 non-null float64
     Cabin          204 non-null object
     Embarked       891 non-null object
     dtypes: float64(2), int64(5), object(5)
     memory usage: 83.6+ KB
     None
     #+end_example
   - Fare
     #+BEGIN_SRC python :results output :session init :tangle yes
     def add_missing_fare(data):
       data["Fare"] = data["Fare"].fillna(data["Fare"].median())
       return data
     print(add_missing_fare(train_data_csv.copy()).info())
     transformations.append(add_missing_fare)
     #+END_SRC

     #+RESULTS:
     #+begin_example
     <class 'pandas.core.frame.DataFrame'>
     RangeIndex: 891 entries, 0 to 890
     Data columns (total 12 columns):
     PassengerId    891 non-null int64
     Survived       891 non-null int64
     Pclass         891 non-null int64
     Name           891 non-null object
     Sex            891 non-null object
     Age            714 non-null float64
     SibSp          891 non-null int64
     Parch          891 non-null int64
     Ticket         891 non-null object
     Fare           891 non-null float64
     Cabin          204 non-null object
     Embarked       891 non-null object
     dtypes: float64(2), int64(5), object(5)
     memory usage: 83.6+ KB
     None
     #+end_example

** Ranges for Age
   - may get similar results by scaling - not adding to the pipeline for now
   #+BEGIN_SRC python :results output :session init :tangle yes
   preprocessed_data["Age"] = np.floor(preprocessed_data['Age'] / 10)
   print(preprocessed_data["Age"].value_counts())
   #+END_SRC

   #+RESULTS:
   #+begin_example
   2.0    220
   3.0    167
   1.0    102
   4.0     89
   0.0     62
   5.0     48
   6.0     19
   7.0      6
   8.0      1
   Name: Age, dtype: int64
   #+end_example

** Cabin Code
   - Use first character of the cabin number as cabin code:
     #+BEGIN_SRC python :results output :session init :tangle yes
     def cabin_code(data):
       data.Cabin = data.Cabin.str.slice(0, 1)
       return data
     print(cabin_code(preprocessed_data.copy()).Cabin.value_counts())
     transformations.append(cabin_code)
     #+END_SRC

     #+RESULTS:
     : C    59
     : B    47
     : D    33
     : E    32
     : A    15
     : F    13
     : G     4
     : T     1
     : Name: Cabin, dtype: int64

** Encoding
    - Sex, not using 1-hot encoding since just 2 values
      #+BEGIN_SRC python :results output :session init :tangle yes
      def encode_sex(data):
        sex_encoder = LabelEncoder()
        data["Sex"] = sex_encoder.fit_transform(data["Sex"])
        return data
      print(encode_sex(preprocessed_data.copy())["Sex"][:5])
      transformations.append(encode_sex)
      #+END_SRC

      #+RESULTS:
      : 0    1
      : 1    0
      : 2    0
      : 3    0
      : 4    1
      : Name: Sex, dtype: int64

    - Cabin, use 1-hot encoding
      #+BEGIN_SRC python :results output :session init :tangle yes
      def encode_cabin(data):
        cabin_encoder = LabelBinarizer()
        data["Cabin"] = cabin_encoder.fit_transform(data["Cabin"])
        return data
      transformations.append(encode_cabin)
      data = preprocessed_data.copy()

      print(data.info())
      #+END_SRC

      #+RESULTS:
      #+begin_example
      <class 'pandas.core.frame.DataFrame'>
      RangeIndex: 891 entries, 0 to 890
      Data columns (total 12 columns):
      PassengerId    891 non-null int64
      Survived       891 non-null int64
      Pclass         891 non-null int64
      Name           891 non-null object
      Sex            891 non-null object
      Age            714 non-null float64
      SibSp          891 non-null int64
      Parch          891 non-null int64
      Ticket         891 non-null object
      Fare           891 non-null float64
      Cabin          204 non-null object
      Embarked       891 non-null object
      dtypes: float64(2), int64(5), object(5)
      memory usage: 83.6+ KB
      None
      #+end_example

** Apply Transformations
   - apply
     #+BEGIN_SRC python :results output :session init :tangle yes
     data = train_data_csv.copy()
     for transformation in transformations:
       data = transformation(data)
     preprocessed_data = data
     print(preprocessed_data.info())
     #+END_SRC

     #+RESULTS:
     #+begin_example
     <class 'pandas.core.frame.DataFrame'>
     RangeIndex: 891 entries, 0 to 890
     Data columns (total 8 columns):
     Survived    891 non-null int64
     Pclass      891 non-null int64
     Sex         891 non-null int64
     Age         891 non-null float64
     SibSp       891 non-null int64
     Parch       891 non-null int64
     Fare        891 non-null float64
     Cabin       891 non-null int64
     dtypes: float64(2), int64(6)
     memory usage: 55.8 KB
     None
     #+end_example

   - Peek
     #+BEGIN_SRC python :results output :session init :tangle yes
     preprocessed_data = data
     print(preprocessed_data.head())
     #+END_SRC

     #+RESULTS:
     : Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Cabin
     : 0         0       3    1  22.0      1      0   7.2500      0
     : 1         1       1    0  38.0      1      0  71.2833      0
     : 2         1       3    0  26.0      0      0   7.9250      0
     : 3         1       1    0  35.0      1      0  53.1000      0
     : 4         0       3    1  35.0      0      0   8.0500      0

* Correlations
  - since original data is not huge, do on all
    #+BEGIN_SRC python :results output :session init :tangle yes
    corr_matrix = train_data_csv.corr()
    print(corr_matrix["Survived"].sort_values(ascending=False))
    #+END_SRC

    #+RESULTS:
    : Survived       1.000000
    : Fare           0.257307
    : Parch          0.081629
    : PassengerId   -0.005007
    : SibSp         -0.035322
    : Age           -0.077221
    : Pclass        -0.338481
    : Name: Survived, dtype: float64

  - on preprocessed data:
    #+BEGIN_SRC python :results output :session init :tangle yes
    pre_corr_matrix = preprocessed_data.corr()
    print(pre_corr_matrix["Survived"].sort_values(ascending=False))
    #+END_SRC

    #+RESULTS:
    : Survived    1.000000
    : Fare        0.257307
    : Parch       0.081629
    : Cabin       0.022287
    : SibSp      -0.035322
    : Age        -0.064910
    : Pclass     -0.338481
    : Sex        -0.543351
    : Name: Survived, dtype: float64

* Train
** Load Test Data
   #+BEGIN_SRC python :results output :session init :tangle yes
   test_data_csv = pd.read_csv(os.path.join(LOCAL_DATA_PATH, "test.csv"))
   test_label = pd.read_csv(os.path.join(LOCAL_DATA_PATH, "gender_submission.csv"))
   test_data = test_data_csv.copy()

   for transformation in transformations:
     test_data = transformation(test_data)
   test_label = test_label.drop("PassengerId", axis=1)

   print(transformations)
   print(test_data.head())
   print(test_label.head())
   print(test_data.info())
   #+END_SRC

   #+RESULTS:
   #+begin_example
   [<function remove_columns at 0x10d6b6510>, <function add_missing_cabin at 0x11f7c4a60>, <function add_missing_age at 0x11f8b1510>, <function cabin_code at 0x11f8b1400>, <function encode_sex at 0x11f8b1598>, <function encode_cabin at 0x11f8b16a8>, <function add_missing_fare at 0x11fc1fc80>]
      Pclass  Sex   Age  SibSp  Parch     Fare  Cabin
   0       3    1  34.5      0      0   7.8292      0
   1       3    0  47.0      1      0   7.0000      0
   2       2    1  62.0      0      0   9.6875      0
   3       3    1  27.0      0      0   8.6625      0
   4       3    0  22.0      1      1  12.2875      0
      Survived
   0         0
   1         1
   2         0
   3         0
   4         1
   <class 'pandas.core.frame.DataFrame'>
   RangeIndex: 418 entries, 0 to 417
   Data columns (total 7 columns):
   Pclass    418 non-null int64
   Sex       418 non-null int64
   Age       418 non-null float64
   SibSp     418 non-null int64
   Parch     418 non-null int64
   Fare      418 non-null float64
   Cabin     418 non-null int64
   dtypes: float64(2), int64(5)
   memory usage: 22.9 KB
   None
   #+end_example

** Create Sets
    #+BEGIN_SRC python :results output :session init :tangle yes
    survived_label = preprocessed_data["Survived"].copy()
    feature_list = preprocessed_data.drop("Survived", axis=1)
    print(survived_label.head(3))
    print(feature_list.head(3))
    #+END_SRC

    #+RESULTS:
    : 0    0
    : 1    1
    : 2    1
    : Name: Survived, dtype: int64
    :    Pclass  Sex   Age  SibSp  Parch     Fare  Cabin
    : 0       3    1  22.0      1      0   7.2500      0
    : 1       1    0  38.0      1      0  71.2833      0
    : 2       3    0  26.0      0      0   7.9250      0

** Decision Tree
   - train
     #+BEGIN_SRC python :results output :session init :tangle yes
     from sklearn.tree import DecisionTreeClassifier

     decision_tree_clf = DecisionTreeClassifier()
     decision_tree_clf.fit(feature_list, survived_label)
     print(decision_tree_clf)
    #+END_SRC

    #+RESULTS:
    : DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
    :             max_features=None, max_leaf_nodes=None,
    :             min_impurity_decrease=0.0, min_impurity_split=None,
    :             min_samples_leaf=1, min_samples_split=2,
    :             min_weight_fraction_leaf=0.0, presort=False, random_state=None,
    :             splitter='best')

   - evaluate:
     #+BEGIN_SRC python :results output :session init :tangle yes
     from sklearn.metrics import mean_squared_error
     survived_predictions = decision_tree_clf.predict(test_data)
     tree_mse = mean_squared_error(test_label, survived_predictions)
     tree_rmse = np.sqrt(tree_mse)
     print(tree_rmse)
     #+END_SRC

     #+RESULTS:
     : 0.42358687104367876

* Feature Scaling
  - Fare, using standardization because it is less affected by outliers
    #+BEGIN_SRC python :results output :session init :tangle yes
    scaler = StandardScaler()
    scaled_feature_list = scaler.fit_transform(feature_list)
    scaled_test_data = scaler.fit_transform(test_data)

    decision_tree_clf = DecisionTreeClassifier()
    decision_tree_clf.fit(scaled_feature_list, survived_label)

    survived_predictions = decision_tree_clf.predict(scaled_test_data)
    tree_mse = mean_squared_error(test_label, survived_predictions)
    tree_rmse = np.sqrt(tree_mse)
    print(tree_rmse)
    #+END_SRC

    #+RESULTS:
    : /home/anurag/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.
    :   return self.partial_fit(X, y)
    : /home/anurag/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.
    :   return self.fit(X, **fit_params).transform(X)
    : /home/anurag/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.
    :   return self.partial_fit(X, y)
    : /home/anurag/.local/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.
    :   return self.fit(X, **fit_params).transform(X)
    : 0.517631706652575
